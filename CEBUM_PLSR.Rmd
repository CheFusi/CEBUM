---
title: "PLSR"
output: html_document
date: "2024-02-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Section 05

## PLS Model

---
title: "05CalibrationModels_PLS_Loop_ARC"
output: html_document
date: "2023-07-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\_ two ways of doing predictions (1) with an existing model that was built some time ago and (2) in this case when you have the spectral and wet chem data and you have to develop the model

Reference data = wet chemistry data of the full 100 samples (being used to develop the model)

QUESTION:

-   What does this portion of the code do?: spectraldata.fin\<-spectraldata[is.element(spectraldata\$SSN, df.f\$SSN),]

-   assuming the file spectral data is reading is referring to the selected samples from section 03?

-   or which method of splitting calibration and training data is used? KS or the random setseed123 used later in this script?

Loading libraries

```{r, warning=FALSE}
##################### Random Forest Modelling #################################
library(randomForest)
library(caret)
library(pls)
library(data.table)
#If package ithir is not available for your version of R
#Use the 3 below lines to install package ithir
# install.packages("devtools") 
# library(devtools)
# install_bitbucket("brendo1001/ithir/pkg") or devtools::install_bitbucket("brendo1001/ithir/pkg")

library(ithir)
#used to extract model statistics like RMSE etc.
#using a function called: goof: see here: https://rdrr.io/rforge/ithir/src/R/goof.R 
library(data.table)
library(dplyr)
library(tidyr)
library(prospectr)
library (globals)
library(stringr)
library(ggplot2)
library(here)

```

Load Reference data

```{r}

# spectraldata=read.csv("Raw_spectra-MIR.csv")
spec_trt <- readRDS("spec_trt_MIR.RDS")
spec_trt <- spec_trt[,-2] #removing the data for the first wavenumber since it's all NAN's


df.f<-readRDS("df.f.RDS")

# threshold_na <- 0.95 #for a 95% cut-off
# 
# df.f<-
#   df.f %>% select(where(~mean(is.na(.)) < threshold_na))

spectraldata.fin.fin<-spec_trt[is.element(spec_trt$SSN, df.f$SSN),] ## FUSI Still unclear what this is for. Changed to reference spec_trt
 
```

## Partial Least Squares Regression

### PLSR Model

```{r, warning=FALSE}

#Available properties to predict
#Incase you want to predict only selected properties,
#get property position by running line 66. Remove hash sign between ")" and "["
#symbols on line 67. Edit properties position and run line 67.
#Always ensure position 1 in always included.

#FUSI EDIT 
# changed the call to reference df.f and not df1 because df.f has columns removed for samples that don't have enough data 
# also removed the columns for char and char type

names(df.f)
slprptr<-names(df.f[-c(2:9)]) #FUSI EDIT: removing metadata columns 

#creating a df with the number of components so I can manually define the
# nc_df <- data.frame (SSN=slprptr[-1],
#                        nc=NA)
# 
# write.csv(nc_df, paste0(getwd(),"/nc_df.csv"),row.names = F)

nc_df <-read.csv("nc_df.csv")

pred<-as.data.frame(spec_trt[,1])
colnames(pred)<-"SSN"


#FUSI EDIT

mdl.stats<-NULL#Model stats container
top_loadings_df_pc1 <- NULL
top_loadings_df_pc2  <- NULL

# Create directory for saving wavenumbers vs. loadings plots
dir.create("Wavenumbers_vs_Loadings_PLSR_MIR")


#FUSI EDIT: started at 10 because of metadata
for(p in 10:length(slprptr)){
#Select properties to predict one at a time and remove NAs  
df.sel<-df.f %>% select(SSN, slprptr[p]) %>% na.omit

df.sel_ <-subset(df.sel, df.sel[,2]>quantile(df.sel[,2], 0.01)&df.sel[,2] <quantile(df.sel[,2], 0.99))

#Plot and print Biochar properties boxplots
boxplot(df.sel[,slprptr[p]], las=2, xlab = slprptr[p], ylab = "")
dir.create("Plots_Boxplots_PLSR_MIR")
png(paste0(getwd(),"/Plots_Boxplots_PLSR_MIR/",slprptr[p],".png"))
print(boxplot(df.sel[,slprptr[p]], las=2, xlab = slprptr[p], ylab = ""))
dev.off()

# Plot and print Biochar properties violin plots
violin_plot <- ggplot(data = df.sel, aes(x = "", y = !!sym(slprptr[p]))) +
  geom_violin(fill = "skyblue", color = "blue") +  # Customize fill and border color
  geom_boxplot(width = 0.1, fill = "white", color = "black") +  # Add box plot for reference
  labs(x = "", y = slprptr[p]) +  # Customize axis labels
  coord_flip() +  # Rotate plot by 90 degrees for horizontal orientation
  theme_minimal() +  # Use a minimal theme
  theme(axis.text.x = element_blank()) +  # Hide x-axis labels
  ggtitle(paste("Violin Plot of", slprptr[p]))  # Add plot title

# Save plot as PNG
ggsave(paste0("Plots_Violinplots_PLSR_MIR/", slprptr[p], ".png"), plot = violin_plot)


# #Split samples inside loop for variables with many NAs
# #Set splitting proportion for the calibration and validation data
set.seed(123)
pool=df.sel[sample(nrow(df.sel), round(0.3*nrow(df.sel),0)), ]
pool<-pool[order(pool$SSN),]
poolid<-pool$SSN

#Get calibration and validation datasets
val_df<-pool
cal_df1 <-subset(df.sel, !(df.sel$SSN %in% val_df$SSN))

# threshold to exclude the extreme 5% values
#KARARI UPDATE; 95% loses too many samples, changed to 99% 
#FUSI UPDATE: this initially used to exclude the high high or low low values from the cal and the val set independently. I think this was leading to really small val datasets sometimes. So I did the exclusion before the split to retain the 70/30 split

cal_df <-subset(cal_df1, cal_df1[,2]>quantile(cal_df1[,2], 0.01)&cal_df1[,2] <quantile(cal_df1[,2], 0.99))
val_df1 <-subset(df.sel, (df.sel$SSN %in% val_df$SSN))
val_df <-subset(val_df1, val_df1[,2]>quantile(val_df1[,2], 0.01)&val_df1[,2] <quantile(val_df1[,2], 0.99))

val_df<-setorder(val_df)
cal_df<-setorder(cal_df)

 # Check if val_df is empty and there are more than 3
  if (nrow(val_df) > 3) { 

#Subset pre-treated spectra by available reference data
val_spec<-spec_trt[is.element(spec_trt$SSN, val_df$SSN),]
cal_spec<-spec_trt[is.element(spec_trt$SSN, cal_df$SSN),]
cal_spec<-cal_spec[order(cal_spec$SSN),]
val_spec<-val_spec[order(val_spec$SSN),]


#Get no of calibration and validation datasets
N_cal<-nrow(cal_spec)
N_val<-nrow(val_spec)

#Model data
Xcal.f=cal_spec[,-1]
Xval.f=val_spec[,-1]
dfcal.f=cal_df[,-1]
dfval.f=val_df[,-1]

####
if (nrow(cal_df) < 25) {
  maxc <- nrow(cal_df) - 1
} else {
  maxc <- 25
}## number of max components

#FUSI EDIT: max was 25
pls.md <- plsr(dfcal.f ~ ., data = Xcal.f, ncomp=maxc, validation = "CV", segments = 10)#10-fold CV
#Each iteration of the cross-validation process involves training the model on 9 of the 10 segments and testing it on the remaining segment, repeating this process 10 times to ensure each segment is used as a test set once.

## plot RMSEP vs. number of components
plot(pls.md, "val", main=slprptr[p]) 

dir.create("Components_plots_PLSR_MIR")
png(paste0(getwd(),"/Components_plots_PLSR_MIR/",slprptr[p],".png"))
print(plot(pls.md, "val", main=slprptr[p]))
dev.off()

# ## no. components to use, the one with the smallest adj RMSEP value
# RMSEP.obj<-RMSEP(pls.md)
# str(RMSEP.obj)
# 
# RMSEP.obj$val[1:2,1,]
# nc <- as.numeric(sub("comps", "", names(which.min(RMSEP.obj$val[1,1,2:dim(RMSEP.obj$val[1:2,1,])[2]]))))

#FUSI EDIT
#Mnually selecting the number of components

nc <- nc_df$nc[which(nc_df$SSN == slprptr[p])]

#Generate relevant model name
md.nm<-paste0("pls.md.", slprptr[p], ".nc", nc)

#Rename model with the looped Biochar property
assign(x = md.nm, value = get("pls.md", pos = .GlobalEnv), pos = .GlobalEnv)

## predict to validation dataset
pls.prd <- predict(pls.md, ncomp = nc, newdata = Xval.f)

## Return prediction statistics
val.stats=round(goof(dfval.f, pls.prd, type = "spec"),3)
val.stats<-bind_cols(Property=paste0(Property=slprptr[p],"_val"), Comps="", N=N_val, val.stats)
val.stats

## calibration statistics
pls.pc <- predict(pls.md, ncomp = nc, newdata = Xcal.f)

pls.cal=round(goof(dfcal.f, pls.pc, type = "spec"),3)
cal.stats<-bind_cols(Property=paste0(Property=slprptr[p],"_cal"), Comps=as.character(nc), N=N_cal, pls.cal)
cal.stats

################### Get model statistics #########################
mdstats<-bind_rows(cal.stats, val.stats)

#Create model stats labels for the plot
#FUSI EDIT: Removed comps from before N because plot was crowded should add back in and only remove in plot below 
slct.stats<-as.data.frame(t(mdstats[,c("Property","N","R2","RMSE","bias","RPIQ" )])) 
names(slct.stats)<-NULL
slct.stats<-bind_cols(rownames(slct.stats),slct.stats[,2])

#FUSI EDIT: added "comps" because it is in slct.stats 
valbls<-paste0(c("N","R2","RMSE","bias","RPIQ"), "\n")
valsts<-paste0(c(slct.stats[2,2],slct.stats[3,2],slct.stats[4,2],slct.stats[5,2],slct.stats[6,2]))
valstats<-paste(valbls,valsts)

#Bind all looped properties model stats
mdl.stats<-bind_rows(mdl.stats,mdstats)


lgth<-length(sort(dfval.f,decreasing=F))

seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)

#Plot validation plot
plot(dfval.f,pls.prd,pch=10,
     xlab=paste('Measured',names(val_df)[2],sep="_"),
     ylab=paste('Predicted',names(val_df)[2],sep="_"), 
     xlim = range(c(dfval.f,pls.prd)),
     ylim = range(c(dfval.f,pls.prd)),
     mtext(valstats[-1],side=3, at=c(seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)))
     )   ## plot the predicted vs. measured in the validation
abline(a = 0, b = 1)


dir.create("Plots_Validationplots_PLSR_MIR")
png(paste0(getwd(),"/Plots_Validationplots_PLSR_MIR/",slprptr[p],".png"))
print(plot(dfval.f,pls.prd,pch=10,
           xlab=paste('Measured',names(val_df)[2],sep="_"),
           ylab=paste('Predicted',names(val_df)[2],sep="_"), 
           xlim = range(c(dfval.f,pls.prd)),
           ylim = range(c(dfval.f,pls.prd)),
           mtext(valstats[-1],side=3, at=c(seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)))
           ))
abline(a = 0, b = 1)
dev.off()


################### Predict all samples #########################
prd.smpls <- predict(pls.md, spec_trt[,-1])

prd<-as.data.frame(prd.smpls)
df.prd<-bind_cols(SSN=rownames(prd),prd[,nc])
colnames(df.prd)<-c("SSN",slprptr[p])

pred<-merge(pred, df.prd, by="SSN", all.x = T)



#FUSI EDIT: extracting top loadings

  # Extract loadings
  loadings <- pls.md$loadings
  
  # Get wavenumbers
  wavenumbers <- rownames(loadings)

# Plot wavenumbers vs. loadings
wavenumbers_numeric <- as.numeric(gsub("`", "", wavenumbers))  # Remove backticks and convert to numeric
plot(wavenumbers_numeric, loadings[, nc], type = "l", xlab = "Wavenumbers", ylab = "Loadings", main = paste("Wavenumbers vs. Loadings for", slprptr[p]), xlim = rev(range(wavenumbers_numeric)))
png(paste0(getwd(), "/Wavenumbers_vs_Loadings_PLSR_MIR/", slprptr[p], "_loadings.png"))
print(plot(wavenumbers_numeric, loadings[, nc], type = "l", xlab = "Wavenumbers", ylab = "Loadings", main = paste("Wavenumbers vs. Loadings for", slprptr[p]), xlim = rev(range(wavenumbers_numeric))))
dev.off()
  
  
  
  # Identify the top loaded variables for each component
  top_loaded_variables_pc1 <- head(names(sort(abs(loadings[, 1]), decreasing = TRUE)), 30)
  top_loaded_variables_pc2 <- head(names(sort(abs(loadings[, 2]), decreasing = TRUE)), 30)
  
  #remove single quotes
  top_loaded_variables_pc1<- gsub("`|'", "", top_loaded_variables_pc1)
  top_loaded_variables_pc2<- gsub("`|'", "", top_loaded_variables_pc2)
  
  # plsce them in a dataframe 
  df_pc1 <- t(data.frame(as.numeric(top_loaded_variables_pc1), stringsAsFactors = FALSE))
  df_pc2 <- t(data.frame(as.numeric(top_loaded_variables_pc2), stringsAsFactors = FALSE))
  
  # Optionally, set the column names
colnames(df_pc1) <- paste0("Loading_", 1:ncol(df_pc1))
colnames(df_pc2) <- paste0("Loading_", 1:ncol(df_pc2))
  
  # Create data frame for PC1 loadings
  df_pc1_var <- data.frame(Response_Variable = slprptr[p])
  
  # Create data frame for PC2 loadings
  df_pc2_var <- data.frame(Response_Variable = slprptr[p])
  
  # Append data frames to the main data frames
  top_loadings_df_pc1 <- bind_rows(top_loadings_df_pc1, bind_cols(df_pc1_var, df_pc1))
  top_loadings_df_pc2 <- bind_rows(top_loadings_df_pc2, bind_cols(df_pc2_var, df_pc2))


  
  } else {
    print(paste("Skipping testing parameter:", slprptr[p], "because val_df is empty."))
  }
}
#FUSI EDIT: End of for loop



```

```{r}

write.csv(top_loadings_df_pc1, paste0(getwd(),"/top_loadings_df_pc1_PLSR_MIR.csv"),row.names = F)
write.csv(top_loadings_df_pc2, paste0(getwd(),"/top_loadings_df_pc2_PLSR_MIR.csv"),row.names = F)
```

## Plotting properties with threshold metrics

```{r}


# Add two new columns based on whether the Property contains "_val" or "_cal"
mdl.stats_PLSR_MIR <- mdl.stats %>%
  mutate(Property_Name = gsub("(_cal|_val).*", "", Property),
         Data_Type = ifelse(grepl("_val", Property), "_val", "_cal"))

#Write model statistics and predicted values to the local drive
write.csv(mdl.stats_PLSR_MIR, paste0(getwd(),"/Model_Statistics_PLSR_MIR.csv"),row.names = F)
write.csv(pred, paste0(getwd(),"/Predicted_Biochar_Properties_PLSR_MIR.csv"),row.names = F)
getwd()

saveRDS(mdl.stats_PLSR_MIR,"mdl.stats_PLSR_MIR.RDS")
```

```{r}

#Select only properties with R2 without NA's

mdl.stats_filtered <- mdl.stats_PLSR_MIR[complete.cases(mdl.stats_PLSR_MIR$R2), ]

# Filter the dataframe based on the conditions

# Group by Property_Name and filter for those with R2 > 0.6 for both _cal and _val
mdl.stats_filtered_0_6 <- mdl.stats_filtered %>%
  group_by(Property_Name) %>%
  filter(!any(is.na(R2) & Data_Type %in% c("_cal", "_val"))) %>%
  filter(all(R2 > 0.6 & Data_Type %in% c("_cal", "_val")))

# Plotting
cal_val_top_plot <- ggplot(mdl.stats_filtered_0_6, aes(x = Property_Name, y = R2, fill = Data_Type, group = Data_Type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  labs(title = "Top Properties with R2 of cal & val > 0.6 PLSR MIR",
       x = "Property",
       y = "R2") +
  theme_minimal() +
   theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels by 45 degrees

# Save the plot
ggsave(paste0(getwd(), "/cal_val_PLSR_MIR", ".png"),
       plot = cal_val_top_plot,
       width = 8,
       height = 6, 
       units = "in",
       dpi = 300)


# Extract relevant columns for the top properties and both _cal and _val data
mdl.stats_table <- mdl.stats_filtered_0_6[mdl.stats_filtered_0_6$Property_Name %in% mdl.stats_filtered_0_6, c("Property_Name", "Data_Type","R2", "RPIQ", "RMSE", "bias", "N")]

# Create a new factor variable to control the order of rows in the table
mdl.stats_table$Property_Name <- factor(mdl.stats_table$Property_Name, levels = top_properties_cal)

# Order the rows based on Property_Name and Data_Type
mdl.stats_table <- mdl.stats_table[order(mdl.stats_table$Property_Name, mdl.stats_table$Data_Type), ]


# Create a table with the top properties, both _cal and _val data
mdl.stats_table_wide <- mdl.stats_table %>%
  pivot_wider(
    id_cols = c("Property_Name"),
    names_from = "Data_Type",
    values_from = c("R2","RPIQ", "RMSE", "bias", "N"),
    names_sep = "_"
  )
# Save the table to a CSV file
write.csv(mdl.stats_table, paste0(getwd(), "/Top_Properties_Stats_PLSR_MIR.csv"), row.names = FALSE)

```
